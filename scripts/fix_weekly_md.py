"""
æ¸…ç†å‘¨æŠ¥æ–‡ä»¶ä¸­çš„è¿‡æœŸå¾®ä¿¡é“¾æ¥

è¯¥è„šæœ¬ä¼šï¼š
1. æ‰«ææ‰€æœ‰å‘¨æŠ¥æ–‡ä»¶ï¼ˆdata/weekly/*.mdï¼‰
2. è¯†åˆ«åŒ…å«ä¸´æ—¶å‚æ•°çš„å¾®ä¿¡é“¾æ¥
3. åˆ é™¤åŒ…å«è¿‡æœŸé“¾æ¥çš„æ–‡ç« æ¡ç›®
"""
import re
from pathlib import Path
from typing import List, Tuple
from loguru import logger


def find_expired_links_in_md(content: str) -> List[Tuple[int, str, str]]:
    """
    åœ¨Markdownå†…å®¹ä¸­æŸ¥æ‰¾åŒ…å«è¿‡æœŸé“¾æ¥çš„æ–‡ç« æ¡ç›®
    
    Returns:
        List[Tuple[int, str, str]]: [(line_number, title, url), ...]
    """
    expired_items = []
    lines = content.split('\n')
    
    i = 0
    while i < len(lines):
        line = lines[i]
        
        # æ£€æŸ¥æ˜¯å¦åŒ…å«è¿‡æœŸé“¾æ¥
        if 'é“¾æ¥ï¼š' in line and 'mp.weixin.qq.com' in line:
            if any(param in line for param in ["timestamp=", "signature=", "src=11"]):
                # æŸ¥æ‰¾å¯¹åº”çš„æ ‡é¢˜ï¼ˆå‘ä¸ŠæŸ¥æ‰¾å‡ è¡Œï¼‰
                title = "æœªçŸ¥æ ‡é¢˜"
                title_line_idx = i
                
                # å‘ä¸ŠæŸ¥æ‰¾æ ‡é¢˜ï¼ˆé€šå¸¸æ˜¯æ•°å­—å¼€å¤´çš„è¡Œï¼Œå¦‚ "1. æ ‡é¢˜"ï¼‰
                for j in range(max(0, i - 3), i):
                    if re.match(r'^\d+\.\s+', lines[j]):
                        title = lines[j].strip()
                        title_line_idx = j
                        break
                
                expired_items.append((title_line_idx, title, line.strip()))
        
        i += 1
    
    return expired_items


def remove_expired_articles_from_md(file_path: Path, dry_run: bool = True) -> dict:
    """
    ä»Markdownæ–‡ä»¶ä¸­åˆ é™¤åŒ…å«è¿‡æœŸé“¾æ¥çš„æ–‡ç« æ¡ç›®
    
    Args:
        file_path: Markdownæ–‡ä»¶è·¯å¾„
        dry_run: å¦‚æœä¸ºTrueï¼Œåªæ˜¾ç¤ºå°†è¦åˆ é™¤çš„å†…å®¹ï¼Œä¸å®é™…åˆ é™¤
    
    Returns:
        Dict: ç»Ÿè®¡ä¿¡æ¯
    """
    logger.info(f"æ­£åœ¨å¤„ç†æ–‡ä»¶: {file_path}")
    
    try:
        with file_path.open("r", encoding="utf-8") as f:
            content = f.read()
    except Exception as e:
        logger.error(f"æ— æ³•è¯»å–æ–‡ä»¶ {file_path}: {e}")
        return {"removed": 0, "total": 0}
    
    # æŸ¥æ‰¾è¿‡æœŸé“¾æ¥
    expired_items = find_expired_links_in_md(content)
    if not expired_items:
        logger.info(f"æ–‡ä»¶ {file_path} ä¸­æ²¡æœ‰æ‰¾åˆ°è¿‡æœŸé“¾æ¥")
        return {"removed": 0, "total": 0}
    
    logger.info(f"æ‰¾åˆ° {len(expired_items)} ä¸ªè¿‡æœŸé“¾æ¥çš„æ¡ç›®")
    
    # æ˜¾ç¤ºå°†è¦åˆ é™¤çš„æ¡ç›®
    for title_line_idx, title, url_line in expired_items:
        logger.warning(f"  [{title_line_idx}] {title[:50]}... | {url_line[:60]}...")
    
    if dry_run:
        logger.info(f"ã€é¢„è§ˆæ¨¡å¼ã€‘å°†ä¼šåˆ é™¤ {len(expired_items)} ä¸ªæ¡ç›®")
        return {"removed": 0, "total": len(expired_items)}
    
    # å®é™…åˆ é™¤è¿‡æœŸæ¡ç›®
    lines = content.split('\n')
    lines_to_remove = set()
    
    for title_line_idx, title, url_line in expired_items:
        # æ‰¾åˆ°éœ€è¦åˆ é™¤çš„è¡ŒèŒƒå›´ï¼ˆä»æ ‡é¢˜è¡Œå¼€å§‹ï¼Œåˆ°ä¸‹ä¸€ä¸ªæ¡ç›®æˆ–ç©ºè¡Œç»“æŸï¼‰
        start_idx = title_line_idx
        
        # æ‰¾åˆ°ç»“æŸä½ç½®ï¼ˆä¸‹ä¸€ä¸ªæ•°å­—å¼€å¤´çš„è¡Œæˆ–ç©ºè¡Œï¼‰
        end_idx = len(lines)
        for i in range(title_line_idx + 1, len(lines)):
            line = lines[i].strip()
            # å¦‚æœé‡åˆ°ç©ºè¡Œï¼Œæ£€æŸ¥ä¸‹ä¸€è¡Œæ˜¯å¦ä¸ºä¸‹ä¸€ä¸ªæ¡ç›®
            if line == '':
                # æ£€æŸ¥ä¸‹ä¸€è¡Œæ˜¯å¦æ˜¯æ–°æ¡ç›®ï¼ˆæ•°å­—å¼€å¤´ï¼‰æˆ–æ–°åˆ†ç±»
                if i + 1 < len(lines):
                    next_line = lines[i + 1].strip()
                    if re.match(r'^\d+\.\s+', next_line) or next_line.startswith('## '):
                        end_idx = i + 1
                        break
            # å¦‚æœé‡åˆ°ä¸‹ä¸€ä¸ªæ•°å­—å¼€å¤´çš„è¡Œï¼ˆåŒä¸€åˆ†ç±»å†…ï¼‰
            elif re.match(r'^\d+\.\s+', line):
                end_idx = i
                break
            # å¦‚æœé‡åˆ°æ–°çš„åˆ†ç±»æ ‡é¢˜
            elif line.startswith('## '):
                end_idx = i
                break
        
        # æ ‡è®°è¦åˆ é™¤çš„è¡Œï¼ˆåŒ…æ‹¬æ ‡é¢˜è¡Œåˆ°é“¾æ¥è¡ŒåŠä¹‹åçš„ç©ºè¡Œï¼‰
        for i in range(start_idx, min(end_idx, len(lines))):
            lines_to_remove.add(i)
    
    # åˆ é™¤æ ‡è®°çš„è¡Œ
    lines_list = [line for i, line in enumerate(lines) if i not in lines_to_remove]
    
    # é‡æ–°ç¼–å·AIèµ„è®¯å’Œç¼–ç¨‹èµ„è®¯éƒ¨åˆ†çš„æ¡ç›®
    current_category = None
    item_num = 0
    
    new_lines = []
    for i, line in enumerate(lines_list):
        # æ£€æµ‹åˆ†ç±»æ ‡é¢˜
        if '## ğŸ¤– AIèµ„è®¯' in line or '## ğŸ’» ç¼–ç¨‹èµ„è®¯' in line:
            current_category = line
            item_num = 0
            new_lines.append(line)
            continue
        
        # å¦‚æœæ˜¯æ•°å­—å¼€å¤´çš„æ¡ç›®ï¼Œé‡æ–°ç¼–å·
        match = re.match(r'^(\d+)\.\s+(.+)', line)
        if match:
            item_num += 1
            new_lines.append(f"{item_num}. {match.group(2)}")
        else:
            new_lines.append(line)
    
    # æ›´æ–°ç»Ÿè®¡ä¿¡æ¯
    content_new = '\n'.join(new_lines)
    
    # æ›´æ–°ç»Ÿè®¡ä¿¡æ¯è¡Œ
    stats_match = re.search(r'æœ¬å‘¨å…±æ¨è\s+(\d+)\s+ç¯‡ä¼˜è´¨èµ„è®¯', content_new)
    if stats_match:
        current_count = int(stats_match.group(1))
        removed_count = len(expired_items)
        new_count = current_count - removed_count
        
        # æ›´æ–°æ€»æ•°
        content_new = re.sub(
            r'æœ¬å‘¨å…±æ¨è\s+\d+\s+ç¯‡ä¼˜è´¨èµ„è®¯',
            f'æœ¬å‘¨å…±æ¨è {new_count} ç¯‡ä¼˜è´¨èµ„è®¯',
            content_new
        )
        
        # ç»Ÿè®¡å®é™…å‰©ä½™çš„æ–‡ç« æ•°é‡
        # æå–AIèµ„è®¯éƒ¨åˆ†
        ai_section_match = re.search(r'## ğŸ¤– AIèµ„è®¯\n\n(.*?)(?=\n\n---|\n\n##)', content_new, re.DOTALL)
        ai_section = ai_section_match.group(1) if ai_section_match else ""
        ai_count = len(re.findall(r'^\d+\.\s+', ai_section, re.MULTILINE))
        
        # æå–ç¼–ç¨‹èµ„è®¯éƒ¨åˆ†
        programming_section_match = re.search(r'## ğŸ’» ç¼–ç¨‹èµ„è®¯\n\n(.*?)(?=\n\n---|\n\nç»Ÿè®¡)', content_new, re.DOTALL)
        programming_section = programming_section_match.group(1) if programming_section_match else ""
        programming_count = len(re.findall(r'^\d+\.\s+', programming_section, re.MULTILINE))
        
        total_count = ai_count + programming_count
        
        # æ›´æ–°æ€»æ•°
        content_new = re.sub(
            r'æœ¬å‘¨å…±æ¨è\s+\d+\s+ç¯‡ä¼˜è´¨èµ„è®¯',
            f'æœ¬å‘¨å…±æ¨è {total_count} ç¯‡ä¼˜è´¨èµ„è®¯',
            content_new
        )
        
        # æ›´æ–°åˆ†ç±»ç»Ÿè®¡
        content_new = re.sub(
            r'-\s+AIèµ„è®¯ï¼š\d+\s+ç¯‡',
            f'- AIèµ„è®¯ï¼š{ai_count} ç¯‡',
            content_new
        )
        content_new = re.sub(
            r'-\s+ç¼–ç¨‹èµ„è®¯ï¼š\d+\s+ç¯‡',
            f'- ç¼–ç¨‹èµ„è®¯ï¼š{programming_count} ç¯‡',
            content_new
        )
    
    # ä¿å­˜æ–‡ä»¶
    try:
        # åˆ›å»ºå¤‡ä»½
        backup_path = file_path.with_suffix(f".md.backup")
        with file_path.open("r", encoding="utf-8") as src, backup_path.open("w", encoding="utf-8") as dst:
            dst.write(src.read())
        logger.info(f"å·²åˆ›å»ºå¤‡ä»½: {backup_path}")
        
        # ä¿å­˜æ›´æ–°åçš„æ–‡ä»¶
        with file_path.open("w", encoding="utf-8") as f:
            f.write(content_new)
        logger.success(f"âœ“ æ–‡ä»¶å·²æ›´æ–°: {file_path}")
    except Exception as e:
        logger.error(f"ä¿å­˜æ–‡ä»¶å¤±è´¥ {file_path}: {e}")
        return {"removed": 0, "total": len(expired_items)}
    
    return {"removed": len(expired_items), "total": len(expired_items)}


def main():
    """ä¸»å‡½æ•°"""
    import sys
    
    # é¡¹ç›®æ ¹ç›®å½•
    project_root = Path(__file__).resolve().parents[1]
    weekly_dir = project_root / "data" / "weekly"
    
    # æŸ¥æ‰¾æ‰€æœ‰å‘¨æŠ¥æ–‡ä»¶
    weekly_files = list(weekly_dir.glob("*.md"))
    
    if not weekly_files:
        logger.warning(f"åœ¨ {weekly_dir} ä¸­æ²¡æœ‰æ‰¾åˆ°å‘¨æŠ¥æ–‡ä»¶")
        return
    
    # æ£€æŸ¥å‘½ä»¤è¡Œå‚æ•°
    dry_run = "--dry-run" in sys.argv or "-n" in sys.argv
    force = "--force" in sys.argv or "-f" in sys.argv
    
    if dry_run:
        logger.info("=" * 60)
        logger.info("ã€é¢„è§ˆæ¨¡å¼ã€‘å°†æ˜¾ç¤ºè¦åˆ é™¤çš„æ¡ç›®ï¼Œä½†ä¸ä¼šå®é™…åˆ é™¤")
        logger.info("=" * 60)
    elif force:
        logger.warning("=" * 60)
        logger.warning("ã€å¼ºåˆ¶æ‰§è¡Œæ¨¡å¼ã€‘å°†åˆ é™¤æ‰€æœ‰è¿‡æœŸé“¾æ¥çš„æ¡ç›®")
        logger.warning("=" * 60)
    else:
        logger.warning("=" * 60)
        logger.warning("ã€å®é™…æ‰§è¡Œæ¨¡å¼ã€‘å°†åˆ é™¤æ‰€æœ‰è¿‡æœŸé“¾æ¥çš„æ¡ç›®")
        logger.warning("è¾“å…¥ 'yes' ç¡®è®¤ç»§ç»­ï¼Œæˆ–ä½¿ç”¨ --dry-run å…ˆé¢„è§ˆï¼Œæˆ–ä½¿ç”¨ --force è·³è¿‡ç¡®è®¤")
        logger.warning("=" * 60)
        confirmation = input("ç¡®è®¤åˆ é™¤ï¼Ÿ(yes/no): ")
        if confirmation.lower() != "yes":
            logger.info("å·²å–æ¶ˆæ“ä½œ")
            return
    
    total_stats = {"removed": 0, "total": 0}
    
    for file_path in weekly_files:
        stats = remove_expired_articles_from_md(file_path, dry_run=dry_run)
        total_stats["removed"] += stats["removed"]
        total_stats["total"] += stats["total"]
        logger.info("")
    
    # æ‰“å°æ€»ç»“
    logger.info("=" * 60)
    if dry_run:
        logger.info("é¢„è§ˆå®Œæˆï¼")
        logger.info(f"æ€»è®¡æ‰¾åˆ°: {total_stats['total']} ä¸ªè¿‡æœŸé“¾æ¥çš„æ¡ç›®")
        logger.info(f"è¿è¡Œè„šæœ¬æ—¶ä¸åŠ  --dry-run å‚æ•°å°†åˆ é™¤è¿™äº›æ¡ç›®")
    else:
        logger.info("åˆ é™¤å®Œæˆï¼")
        logger.info(f"æ€»è®¡åˆ é™¤: {total_stats['removed']} ä¸ªæ¡ç›®")
    logger.info("=" * 60)


if __name__ == "__main__":
    main()

