"""
æ¯å‘¨èµ„è®¯æ¨èåŠŸèƒ½
å½“æœ‰èµ„è®¯è¢«é‡‡çº³æˆ–å½’æ¡£æ—¶ï¼Œè‡ªåŠ¨æ›´æ–°æœ¬å‘¨çš„Markdownæ–‡ä»¶
"""
import json
import re
from pathlib import Path
from datetime import datetime, timedelta
from typing import List, Dict, Optional
from loguru import logger

# æ•°æ®ç›®å½•è·¯å¾„
DATA_DIR = Path(__file__).resolve().parent.parent.parent / "data"
WEEKLY_DIR = DATA_DIR / "weekly"
ARTICLES_DIR = DATA_DIR / "articles"


def get_week_number(date: Optional[datetime] = None) -> tuple[int, int]:
    """
    è·å–æŒ‡å®šæ—¥æœŸæ‰€åœ¨çš„å¹´ä»½å’Œç¬¬å‡ å‘¨
    
    Args:
        date: æ—¥æœŸï¼Œå¦‚æœä¸ºNoneåˆ™ä½¿ç”¨å½“å‰æ—¥æœŸ
    
    Returns:
        (å¹´ä»½, å‘¨æ•°) å…ƒç»„ï¼Œä¾‹å¦‚ (2025, 47)
    """
    if date is None:
        date = datetime.now()
    
    # ä½¿ç”¨ ISO 8601 æ ‡å‡†è®¡ç®—å‘¨æ•°
    # ISO 8601: å‘¨ä¸€ä¸ºä¸€å‘¨çš„å¼€å§‹ï¼Œç¬¬ä¸€å‘¨æ˜¯åŒ…å«1æœˆ4æ—¥çš„é‚£ä¸€å‘¨
    year, week, _ = date.isocalendar()
    return year, week


def get_weekly_filename(year: int, week: int) -> str:
    """
    è·å–å‘¨æŠ¥æ–‡ä»¶å
    
    Args:
        year: å¹´ä»½
        week: å‘¨æ•°
    
    Returns:
        æ–‡ä»¶åï¼Œä¾‹å¦‚ "2025weekly47.md"
    """
    return f"{year}weekly{week}.md"


def get_weekly_filepath(year: int, week: int) -> Path:
    """
    è·å–å‘¨æŠ¥æ–‡ä»¶è·¯å¾„
    
    Args:
        year: å¹´ä»½
        week: å‘¨æ•°
    
    Returns:
        æ–‡ä»¶è·¯å¾„
    """
    WEEKLY_DIR.mkdir(exist_ok=True)
    filename = get_weekly_filename(year, week)
    return WEEKLY_DIR / filename


def get_this_week_articles() -> Dict[str, List[Dict]]:
    """
    è·å–æœ¬å‘¨æ–°å¢çš„èµ„è®¯ï¼ˆAIèµ„è®¯å’Œç¼–ç¨‹èµ„è®¯ï¼‰
    
    Returns:
        {
            "ai_news": [...],  # AIèµ„è®¯åˆ—è¡¨
            "programming": [...]  # ç¼–ç¨‹èµ„è®¯åˆ—è¡¨
        }
    """
    year, week = get_week_number()
    
    # è®¡ç®—æœ¬å‘¨çš„å¼€å§‹æ—¶é—´ï¼ˆå‘¨ä¸€ 00:00:00ï¼‰
    today = datetime.now()
    days_since_monday = today.weekday()  # 0=Monday, 6=Sunday
    week_start = today - timedelta(days=days_since_monday)
    week_start = week_start.replace(hour=0, minute=0, second=0, microsecond=0)
    
    # è®¡ç®—æœ¬å‘¨çš„ç»“æŸæ—¶é—´ï¼ˆå‘¨æ—¥ 23:59:59ï¼‰
    week_end = week_start + timedelta(days=6, hours=23, minutes=59, seconds=59)
    
    logger.debug(f"[å‘¨æŠ¥] æœ¬å‘¨æ—¶é—´èŒƒå›´: {week_start} åˆ° {week_end}")
    
    # åŠ è½½AIèµ„è®¯
    ai_news_file = ARTICLES_DIR / "ai_news.json"
    ai_news = []
    if ai_news_file.exists():
        with open(ai_news_file, 'r', encoding='utf-8') as f:
            ai_news = json.load(f)
    
    # åŠ è½½ç¼–ç¨‹èµ„è®¯
    programming_file = ARTICLES_DIR / "programming.json"
    programming = []
    if programming_file.exists():
        with open(programming_file, 'r', encoding='utf-8') as f:
            programming = json.load(f)
    
    # ç­›é€‰æœ¬å‘¨æ–°å¢çš„èµ„è®¯
    def is_this_week(article: Dict) -> bool:
        """åˆ¤æ–­æ–‡ç« æ˜¯å¦åœ¨æœ¬å‘¨"""
        archived_at = article.get("archived_at")
        if not archived_at:
            return False
        
        try:
            # è§£ææ—¶é—´æˆ³
            if isinstance(archived_at, str):
                # å°è¯•è§£æ ISO æ ¼å¼
                try:
                    # å¤„ç†å¸¦Zçš„ISOæ ¼å¼
                    if archived_at.endswith('Z'):
                        archived_at_clean = archived_at[:-1]
                    else:
                        archived_at_clean = archived_at
                    article_time = datetime.fromisoformat(archived_at_clean)
                except ValueError:
                    # å¦‚æœè§£æå¤±è´¥ï¼Œå°è¯•å…¶ä»–æ ¼å¼
                    try:
                        article_time = datetime.strptime(archived_at, "%Y-%m-%dT%H:%M:%S")
                    except ValueError:
                        logger.warning(f"[å‘¨æŠ¥] æ— æ³•è§£ææ—¶é—´æ ¼å¼: {archived_at}")
                        return False
            else:
                # å‡è®¾æ˜¯æ—¶é—´æˆ³
                article_time = datetime.fromtimestamp(archived_at)
            
            # è½¬æ¢ä¸ºæœ¬åœ°æ—¶é—´ï¼ˆå¦‚æœéœ€è¦ï¼‰
            if article_time.tzinfo:
                article_time = article_time.replace(tzinfo=None)
            
            return week_start <= article_time <= week_end
        except Exception as e:
            logger.warning(f"[å‘¨æŠ¥] è§£ææ–‡ç« æ—¶é—´å¤±è´¥: {archived_at}, é”™è¯¯: {e}")
            return False
    
    ai_news_this_week = [a for a in ai_news if is_this_week(a)]
    programming_this_week = [a for a in programming if is_this_week(a)]
    
    logger.info(f"[å‘¨æŠ¥] æœ¬å‘¨æ–°å¢èµ„è®¯: AIèµ„è®¯ {len(ai_news_this_week)} ç¯‡, ç¼–ç¨‹èµ„è®¯ {len(programming_this_week)} ç¯‡")
    
    return {
        "ai_news": ai_news_this_week,
        "programming": programming_this_week,
    }


def format_article_for_wechat(article: Dict, index: int) -> str:
    """
    æ ¼å¼åŒ–å•ç¯‡æ–‡ç« ä¸ºå¾®ä¿¡å…¬ä¼—å·æ ¼å¼
    
    Args:
        article: æ–‡ç« æ•°æ®
        index: åºå·
    
    Returns:
        æ ¼å¼åŒ–åçš„Markdownå­—ç¬¦ä¸²
    """
    title = article.get("title", "æ— æ ‡é¢˜")
    url = article.get("url", "")
    source = article.get("source", "æœªçŸ¥æ¥æº")
    summary = article.get("summary", "")
    
    # å¾®ä¿¡å…¬ä¼—å·æ ¼å¼ï¼šä½¿ç”¨æ•°å­—åºå·å’Œé“¾æ¥
    # æ³¨æ„ï¼šå¾®ä¿¡å…¬ä¼—å·ä¸æ”¯æŒMarkdowné“¾æ¥ï¼Œæ‰€ä»¥ä½¿ç”¨çº¯æ–‡æœ¬æ ¼å¼
    result = f"{index}. {title}\n"
    if summary:
        # é™åˆ¶æ‘˜è¦é•¿åº¦ï¼Œé¿å…è¿‡é•¿
        summary_short = summary[:100] + "..." if len(summary) > 100 else summary
        result += f"   {summary_short}\n"
    result += f"   æ¥æºï¼š{source}\n"
    result += f"   é“¾æ¥ï¼š{url}\n"
    
    return result


def generate_weekly_markdown(year: int, week: int) -> str:
    """
    ç”Ÿæˆå‘¨æŠ¥Markdownå†…å®¹
    
    Args:
        year: å¹´ä»½
        week: å‘¨æ•°
    
    Returns:
        Markdownå†…å®¹
    """
    articles = get_this_week_articles()
    ai_news = articles["ai_news"]
    programming = articles["programming"]
    
    # è®¡ç®—æœ¬å‘¨çš„æ—¥æœŸèŒƒå›´
    today = datetime.now()
    days_since_monday = today.weekday()
    week_start = today - timedelta(days=days_since_monday)
    week_end = week_start + timedelta(days=6)
    
    week_start_str = week_start.strftime("%Yå¹´%mæœˆ%dæ—¥")
    week_end_str = week_end.strftime("%Yå¹´%mæœˆ%dæ—¥")
    
    # ç”ŸæˆMarkdownå†…å®¹ï¼ˆé€‚åˆå¾®ä¿¡å…¬ä¼—å·æ ¼å¼ï¼‰
    markdown = f"""# ç¬¬{week}å‘¨èµ„è®¯æ¨è

æ—¶é—´èŒƒå›´ï¼š{week_start_str} - {week_end_str}

---

## ğŸ¤– AIèµ„è®¯

"""
    
    if ai_news:
        for i, article in enumerate(ai_news, 1):
            markdown += format_article_for_wechat(article, i) + "\n"
    else:
        markdown += "æœ¬å‘¨æš‚æ— AIèµ„è®¯ã€‚\n\n"
    
    markdown += "\n---\n\n## ğŸ’» ç¼–ç¨‹èµ„è®¯\n\n"
    
    if programming:
        for i, article in enumerate(programming, 1):
            markdown += format_article_for_wechat(article, i) + "\n"
    else:
        markdown += "æœ¬å‘¨æš‚æ— ç¼–ç¨‹èµ„è®¯ã€‚\n\n"
    
    markdown += f"""
---

ç»Ÿè®¡ä¿¡æ¯ï¼š
æœ¬å‘¨å…±æ¨è {len(ai_news) + len(programming)} ç¯‡ä¼˜è´¨èµ„è®¯
- AIèµ„è®¯ï¼š{len(ai_news)} ç¯‡
- ç¼–ç¨‹èµ„è®¯ï¼š{len(programming)} ç¯‡

---
æœ¬æŠ¥å‘Šç”± [AI-CodeNexus](https://aicoding.100kwhy.fun) è‡ªåŠ¨ç”Ÿæˆ
"""
    
    return markdown


def delete_article_from_weekly(url: str) -> bool:
    """
    ä»å½“å‰å‘¨æŠ¥ä¸­åˆ é™¤æŒ‡å®šURLçš„æ–‡ç« 
    
    Args:
        url: è¦åˆ é™¤çš„æ–‡ç« URL
        
    Returns:
        æ˜¯å¦æˆåŠŸåˆ é™¤
    """
    try:
        year, week = get_week_number()
        filepath = get_weekly_filepath(year, week)
        
        if not filepath.exists():
            logger.warning(f"å‘¨æŠ¥æ–‡ä»¶ä¸å­˜åœ¨: {filepath}")
            return False
        
        # è¯»å–å‘¨æŠ¥å†…å®¹
        with open(filepath, 'r', encoding='utf-8') as f:
            content = f.read()
        
        lines = content.split('\n')
        url_to_delete = url.strip()
        
        # æŸ¥æ‰¾å¹¶åˆ é™¤åŒ…å«è¯¥URLçš„è¡Œ
        new_lines = []
        skip_until_number = False
        i = 0
        
        while i < len(lines):
            line = lines[i]
            
            # æ£€æŸ¥æ˜¯å¦åŒ…å«è¦åˆ é™¤çš„URL
            if url_to_delete in line:
                # æ‰¾åˆ°åŒ…å«URLçš„è¡Œï¼Œéœ€è¦åˆ é™¤æ•´ä¸ªæ¡ç›®
                # å‘ä¸ŠæŸ¥æ‰¾æ¡ç›®å¼€å§‹ï¼ˆæ•°å­—å¼€å¤´çš„è¡Œï¼‰
                start_idx = i
                for j in range(i - 1, -1, -1):
                    if re.match(r'^\d+\.\s+', lines[j]):
                        start_idx = j
                        break
                    # å¦‚æœé‡åˆ°ç©ºè¡Œï¼Œåœæ­¢
                    if lines[j].strip() == '' and j < i - 1:
                        break
                
                # å‘ä¸‹æŸ¥æ‰¾æ¡ç›®ç»“æŸï¼ˆä¸‹ä¸€ä¸ªæ•°å­—å¼€å¤´çš„è¡Œæˆ–ç©ºè¡Œåçš„æ•°å­—è¡Œï¼‰
                end_idx = i + 1
                for j in range(i + 1, len(lines)):
                    if re.match(r'^\d+\.\s+', lines[j]):
                        end_idx = j
                        break
                    # å¦‚æœé‡åˆ°ç©ºè¡Œåè·Ÿæ•°å­—è¡Œï¼Œä¹Ÿåœæ­¢
                    if lines[j].strip() == '' and j + 1 < len(lines):
                        if re.match(r'^\d+\.\s+', lines[j + 1]):
                            end_idx = j + 1
                            break
                    # å¦‚æœé‡åˆ°åˆ†éš”ç¬¦æˆ–ç»Ÿè®¡ä¿¡æ¯ï¼Œä¹Ÿåœæ­¢
                    if lines[j].strip().startswith('---') or lines[j].strip().startswith('ç»Ÿè®¡ä¿¡æ¯'):
                        end_idx = j
                        break
                
                # è·³è¿‡è¦åˆ é™¤çš„æ¡ç›®
                i = end_idx
                continue
            
            new_lines.append(line)
            i += 1
        
        # é‡æ–°ç¼–å·å‰©ä½™çš„æ¡ç›®
        current_category = None
        item_num = 0
        final_lines = []
        
        for line in new_lines:
            # æ£€æµ‹åˆ†ç±»æ ‡é¢˜
            if '## ğŸ¤– AIèµ„è®¯' in line or '## ğŸ’» ç¼–ç¨‹èµ„è®¯' in line:
                current_category = line
                item_num = 0
                final_lines.append(line)
                continue
            
            # å¦‚æœæ˜¯æ•°å­—å¼€å¤´çš„æ¡ç›®ï¼Œé‡æ–°ç¼–å·
            match = re.match(r'^(\d+)\.\s+(.+)', line)
            if match:
                item_num += 1
                final_lines.append(f"{item_num}. {match.group(2)}")
            else:
                final_lines.append(line)
        
        # æ›´æ–°ç»Ÿè®¡ä¿¡æ¯
        content_new = '\n'.join(final_lines)
        
        # ç»Ÿè®¡å®é™…å‰©ä½™çš„æ–‡ç« æ•°é‡
        ai_section_match = re.search(r'## ğŸ¤– AIèµ„è®¯\n\n(.*?)(?=\n\n---|\n\n##)', content_new, re.DOTALL)
        programming_section_match = re.search(r'## ğŸ’» ç¼–ç¨‹èµ„è®¯\n\n(.*?)(?=\n\n---|\n\nç»Ÿè®¡)', content_new, re.DOTALL)
        
        ai_count = len(re.findall(r'^\d+\.\s+', ai_section_match.group(1) if ai_section_match else "", re.MULTILINE))
        programming_count = len(re.findall(r'^\d+\.\s+', programming_section_match.group(1) if programming_section_match else "", re.MULTILINE))
        total_count = ai_count + programming_count
        
        # æ›´æ–°æ€»æ•°
        content_new = re.sub(
            r'æœ¬å‘¨å…±æ¨è\s+\d+\s+ç¯‡ä¼˜è´¨èµ„è®¯',
            f'æœ¬å‘¨å…±æ¨è {total_count} ç¯‡ä¼˜è´¨èµ„è®¯',
            content_new
        )
        
        # æ›´æ–°åˆ†ç±»ç»Ÿè®¡
        content_new = re.sub(
            r'-\s+AIèµ„è®¯ï¼š\d+\s+ç¯‡',
            f'- AIèµ„è®¯ï¼š{ai_count} ç¯‡',
            content_new
        )
        content_new = re.sub(
            r'-\s+ç¼–ç¨‹èµ„è®¯ï¼š\d+\s+ç¯‡',
            f'- ç¼–ç¨‹èµ„è®¯ï¼š{programming_count} ç¯‡',
            content_new
        )
        
        # ä¿å­˜æ›´æ–°åçš„å‘¨æŠ¥
        with open(filepath, 'w', encoding='utf-8') as f:
            f.write(content_new)
        
        logger.info(f"ä»å‘¨æŠ¥ä¸­åˆ é™¤æ–‡ç« : {url_to_delete[:60]}...")
        return True
        
    except Exception as e:
        logger.error(f"ä»å‘¨æŠ¥åˆ é™¤æ–‡ç« å¤±è´¥: {e}", exc_info=True)
        return False


def update_weekly_digest() -> bool:
    """
    æ›´æ–°æœ¬å‘¨çš„å‘¨æŠ¥Markdownæ–‡ä»¶
    å½“æœ‰èµ„è®¯è¢«é‡‡çº³æˆ–å½’æ¡£æ—¶è°ƒç”¨æ­¤å‡½æ•°
    
    Returns:
        æ˜¯å¦æˆåŠŸæ›´æ–°
    """
    try:
        year, week = get_week_number()
        filepath = get_weekly_filepath(year, week)
        
        logger.info(f"[å‘¨æŠ¥] å¼€å§‹æ›´æ–°å‘¨æŠ¥: {get_weekly_filename(year, week)}")
        
        # ç”ŸæˆMarkdownå†…å®¹
        markdown = generate_weekly_markdown(year, week)
        
        # ä¿å­˜åˆ°æ–‡ä»¶
        with open(filepath, 'w', encoding='utf-8') as f:
            f.write(markdown)
        
        logger.info(f"[å‘¨æŠ¥] å‘¨æŠ¥å·²æ›´æ–°: {filepath}")
        return True
        
    except Exception as e:
        logger.error(f"[å‘¨æŠ¥] æ›´æ–°å‘¨æŠ¥å¤±è´¥: {e}", exc_info=True)
        return False

