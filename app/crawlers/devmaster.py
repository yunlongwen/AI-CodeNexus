"""DevMaster.cn å·¥å…·æŠ“å–å™¨"""
import asyncio
from datetime import datetime
from typing import List, Dict, Any, Optional
from urllib.parse import urljoin, urlparse

import httpx
from bs4 import BeautifulSoup
from loguru import logger
from playwright.async_api import async_playwright, TimeoutError as PlaywrightTimeoutError


# åˆ†ç±»æ˜ å°„ï¼šå°† devmaster.cn çš„åˆ†ç±»æ˜ å°„åˆ°æˆ‘ä»¬çš„åˆ†ç±»
CATEGORY_MAPPING = {
    "ide": ["IDE", "ç¼–è¾‘å™¨", "å¼€å‘ç¯å¢ƒ"],
    "plugin": ["æ’ä»¶", "æ‰©å±•", "Extension"],
    "cli": ["å‘½ä»¤è¡Œ", "CLI", "ç»ˆç«¯", "Terminal"],
    "codeagent": ["AIåŠ©æ‰‹", "CodeAgent", "AIä»£ç ", "æ™ºèƒ½ç¼–ç¨‹"],
    "ai-test": ["AIæµ‹è¯•", "æµ‹è¯•å·¥å…·", "è‡ªåŠ¨åŒ–æµ‹è¯•"],
    "review": ["ä»£ç å®¡æŸ¥", "Code Review", "ä»£ç è´¨é‡"],
    "devops": ["DevOps", "CI/CD", "éƒ¨ç½²", "è¿ç»´"],
    "doc": ["æ–‡æ¡£", "æ–‡æ¡£å·¥å…·", "Documentation", "Docs"],
    "design": ["è®¾è®¡", "UIè®¾è®¡", "UXè®¾è®¡"],
    "ui": ["UIç”Ÿæˆ", "ç•Œé¢ç”Ÿæˆ", "UIå·¥å…·", "VibeTool"],
    "mcp": ["MCP", "Model Context Protocol"],
    "other": []  # å…¶ä»–æœªåˆ†ç±»çš„å·¥å…·
}

# APIåˆ†ç±»åˆ°æˆ‘ä»¬åˆ†ç±»çš„æ˜ å°„
API_CATEGORY_MAPPING = {
    "VibeTool": "other",  # VibeTool æ˜ å°„åˆ° otherï¼ŒUIç”ŸæˆåªåŒ…å« UI-Code
    "UI-Code": "ui",  # UI-Code æ˜ å°„åˆ° uiï¼ˆUIç”Ÿæˆï¼‰
    "Docs": "doc",
    "IDE": "ide",
    "Plugin": "plugin",
    "Extension": "plugin",
    "CLI": "cli",
    "CliAgent": "cli",
    "CodeAgent": "codeagent",
    "AITest": "ai-test",
    "Testing": "ai-test",  # Testing åˆ†ç±»æ˜ å°„åˆ° ai-test
    "Review": "review",
    "CodeReview": "review",
    "DevOps": "devops",
    "Design": "design",
    "MCP": "mcp",
    "McpTool": "mcp",
    "Resource": "other",
    "Other": "other",
}


def _map_api_category(api_category: str) -> str:
    """
    å°†APIè¿”å›çš„åˆ†ç±»æ˜ å°„åˆ°æˆ‘ä»¬çš„åˆ†ç±»ç³»ç»Ÿ
    
    Args:
        api_category: APIè¿”å›çš„åˆ†ç±»åç§°
        
    Returns:
        æ˜ å°„åçš„åˆ†ç±»åç§°
    """
    if not api_category:
        return "other"
    
    # ç›´æ¥æ˜ å°„
    api_category_clean = api_category.strip()
    if api_category_clean in API_CATEGORY_MAPPING:
        return API_CATEGORY_MAPPING[api_category_clean]
    
    # æ¨¡ç³ŠåŒ¹é…
    api_category_lower = api_category_clean.lower()
    for our_category, keywords in CATEGORY_MAPPING.items():
        for keyword in keywords:
            if keyword.lower() in api_category_lower or api_category_lower in keyword.lower():
                return our_category
    
    return "other"


async def fetch_devmaster_tools(
    category: Optional[str] = None,
    max_items: int = 100,
    use_api: bool = True,
    use_playwright: bool = False
) -> List[Dict[str, Any]]:
    """
    ä» DevMaster.cn æŠ“å–å·¥å…·æ•°æ®
    
    Args:
        category: å·¥å…·åˆ†ç±»ï¼ˆå¯é€‰ï¼‰
        max_items: æœ€å¤šæŠ“å–çš„å·¥å…·æ•°é‡
        use_api: æ˜¯å¦ä¼˜å…ˆä½¿ç”¨APIï¼ˆæ¨èï¼‰
        use_playwright: æ˜¯å¦ä½¿ç”¨ Playwrightï¼ˆå½“APIä¸å¯ç”¨æ—¶ï¼‰
        
    Returns:
        å·¥å…·åˆ—è¡¨ï¼Œæ¯ä¸ªå·¥å…·åŒ…å« name, url, description, category, tags, icon ç­‰
    """
    # ä¼˜å…ˆä½¿ç”¨API
    if use_api:
        tools = await fetch_tools_from_api()
        if tools:
            # å¦‚æœæŒ‡å®šäº†åˆ†ç±»ï¼Œè¿›è¡Œç­›é€‰
            if category:
                tools = [t for t in tools if t.get("category") == category]
            # é™åˆ¶æ•°é‡
            if max_items:
                tools = tools[:max_items]
            return tools
    
    # APIå¤±è´¥æ—¶ä½¿ç”¨Playwright
    if use_playwright:
        return await _fetch_with_playwright(category, max_items)
    else:
        return await _fetch_with_httpx(category, max_items)


async def _fetch_with_playwright(
    category: Optional[str] = None,
    max_items: int = 100
) -> List[Dict[str, Any]]:
    """ä½¿ç”¨ Playwright æŠ“å–å·¥å…·æ•°æ®"""
    base_url = "http://devmaster.cn"
    tools_url = f"{base_url}/tools" if category is None else f"{base_url}/category/{category}"
    
    logger.info(f"ä½¿ç”¨ Playwright è®¿é—® {tools_url}...")
    tools = []
    
    try:
        async with async_playwright() as p:
            browser = await p.chromium.launch(headless=True)
            context = await browser.new_context(
                user_agent="Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36"
            )
            page = await context.new_page()
            
            # è®¿é—®å·¥å…·é¡µé¢
            await page.goto(tools_url, wait_until="networkidle", timeout=30000)
            
            # ç­‰å¾…å†…å®¹åŠ è½½
            await page.wait_for_timeout(2000)
            
            # è·å–é¡µé¢å†…å®¹
            html = await page.content()
            soup = BeautifulSoup(html, 'html.parser')
            
            # å°è¯•å¤šç§é€‰æ‹©å™¨
            tool_elements = []
            selectors = [
                "article",
                "[class*='card']",
                "[class*='item']",
                "[class*='tool']",
                ".tool-card",
                ".product-item"
            ]
            
            for selector in selectors:
                elements = soup.select(selector)
                if elements and len(elements) > 3:  # è‡³å°‘è¦æœ‰å‡ ä¸ªå…ƒç´ æ‰è®¤ä¸ºæ˜¯å·¥å…·åˆ—è¡¨
                    logger.info(f"æ‰¾åˆ° {len(elements)} ä¸ªå·¥å…·å…ƒç´ ï¼ˆé€‰æ‹©å™¨: {selector}ï¼‰")
                    tool_elements = elements
                    break
            
            if not tool_elements:
                logger.warning("æœªæ‰¾åˆ°å·¥å…·åˆ—è¡¨ï¼Œå°è¯•ä»APIè·å–...")
                # å°è¯•æŸ¥æ‰¾APIè°ƒç”¨
                tools = await _try_fetch_from_api(page, base_url)
                if tools:
                    return tools
            
            # è§£æå·¥å…·å…ƒç´ 
            logger.info(f"å¼€å§‹è§£æ {len(tool_elements)} ä¸ªå·¥å…·å…ƒç´ ...")
            for idx, element in enumerate(tool_elements[:max_items]):
                try:
                    tool = _parse_tool_element(element, base_url)
                    if tool:
                        if not category:
                            tool["category"] = _auto_categorize_tool(tool)
                        else:
                            tool["category"] = category
                        tools.append(tool)
                        logger.debug(f"è§£æå·¥å…· {idx+1}/{len(tool_elements)}: {tool.get('name', 'Unknown')}")
                except Exception as e:
                    logger.warning(f"è§£æå·¥å…·å…ƒç´ å¤±è´¥: {e}")
                    continue
            
            await browser.close()
            
    except PlaywrightTimeoutError:
        logger.error(f"è®¿é—® {tools_url} è¶…æ—¶")
    except Exception as e:
        logger.error(f"Playwright æŠ“å–å¤±è´¥: {e}")
        import traceback
        logger.debug(traceback.format_exc())
    
    logger.info(f"ä» DevMaster.cn æˆåŠŸæŠ“å–åˆ° {len(tools)} ä¸ªå·¥å…·")
    return tools


async def _try_fetch_from_api(page, base_url: str) -> List[Dict[str, Any]]:
    """å°è¯•ä»APIè·å–å·¥å…·æ•°æ®"""
    return await fetch_tools_from_api(base_url=base_url)


async def fetch_tools_from_api(api_url: Optional[str] = None, base_url: Optional[str] = None) -> List[Dict[str, Any]]:
    """
    ç›´æ¥ä»APIè·å–å·¥å…·æ•°æ®ï¼ˆæ¨èæ–¹æ³•ï¼‰
    
    Args:
        api_url: å®Œæ•´çš„API URLï¼ˆä¼˜å…ˆä½¿ç”¨ï¼‰
        base_url: ç½‘ç«™åŸºç¡€URLï¼ˆå¦‚æœæœªæä¾›api_urlï¼Œåˆ™ä½¿ç”¨base_urlæ‹¼æ¥/api/toolsï¼‰
        
    Returns:
        å·¥å…·åˆ—è¡¨
    """
    # ä¼˜å…ˆä½¿ç”¨ api_urlï¼Œå¦‚æœæ²¡æœ‰åˆ™ä½¿ç”¨ base_url æ‹¼æ¥
    if not api_url:
        if base_url:
            api_url = f"{base_url.rstrip('/')}/api/tools"
        else:
            # å…¼å®¹æ—§ä»£ç ï¼Œä½¿ç”¨é»˜è®¤å€¼ï¼ˆä½†ä¸æ¨èï¼‰
            api_url = "http://devmaster.cn/api/tools"
    tools = []
    
    try:
        async with httpx.AsyncClient(
            timeout=30.0,
            headers={
                "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36",
                "Accept": "application/json",
            }
        ) as client:
            logger.info(f"ä»APIè·å–å·¥å…·æ•°æ®: {api_url}")
            resp = await client.get(api_url)
            resp.raise_for_status()
            
            data = resp.json()
            
            # å¤„ç†ä¸åŒçš„APIå“åº”æ ¼å¼
            items = []
            if isinstance(data, dict):
                # æ ¼å¼: {"code": 200, "msg": "success", "data": {...}}
                if "data" in data:
                    data_content = data["data"]
                    # data å¯èƒ½æ˜¯åˆ—è¡¨æˆ–å­—å…¸
                    if isinstance(data_content, list):
                        items = data_content
                    elif isinstance(data_content, dict):
                        # æ ¼å¼: {"items": [...], "total": 100, ...}
                        if "items" in data_content:
                            items = data_content["items"]
                        else:
                            logger.warning(f"dataå­—æ®µæ˜¯å­—å…¸ä½†æ²¡æœ‰itemsé”®: {list(data_content.keys())}")
                    else:
                        logger.warning(f"dataå­—æ®µç±»å‹æœªçŸ¥: {type(data_content)}")
                elif "items" in data:
                    items = data["items"]
                else:
                    logger.warning(f"å“åº”å­—å…¸ä¸­æ²¡æœ‰dataæˆ–itemsé”®: {list(data.keys())}")
            elif isinstance(data, list):
                items = data
            else:
                logger.warning(f"æœªçŸ¥çš„APIå“åº”æ ¼å¼: {type(data)}")
                return []
            
            logger.info(f"APIè¿”å› {len(items)} ä¸ªå·¥å…·é¡¹")
            
            for item in items:
                try:
                    # å¤„ç†æ—¶é—´æˆ³ï¼ˆæ¯«ç§’ï¼‰
                    update_time = item.get("updateTime")
                    if update_time:
                        # å°†æ¯«ç§’æ—¶é—´æˆ³è½¬æ¢ä¸ºISOæ ¼å¼
                        try:
                            dt = datetime.fromtimestamp(update_time / 1000)
                            created_at = dt.isoformat() + "Z"
                        except (ValueError, TypeError):
                            created_at = datetime.now().isoformat() + "Z"
                    else:
                        created_at = datetime.now().isoformat() + "Z"
                    
                    # æ˜ å°„åˆ†ç±»
                    api_category = item.get("category", "").strip()
                    mapped_category = _map_api_category(api_category)
                    
                    tool = {
                        "name": item.get("name", "").strip(),
                        "url": item.get("url", "").strip(),
                        "description": item.get("description", "").strip(),
                        "category": mapped_category,
                        "tags": item.get("tags", []) or [],
                        "icon": item.get("icon", "ğŸ”§"),
                        "view_count": item.get("view_count", 0),
                        "created_at": created_at,
                        "is_featured": item.get("is_featured", False)
                    }
                    
                    # éªŒè¯å¿…éœ€å­—æ®µ
                    if tool["name"] and tool["url"]:
                        tools.append(tool)
                    else:
                        logger.debug(f"è·³è¿‡æ— æ•ˆå·¥å…·: {item}")
                except Exception as e:
                    logger.warning(f"è§£æå·¥å…·é¡¹å¤±è´¥: {e}, item: {item}")
                    continue
            
            logger.info(f"æˆåŠŸè§£æ {len(tools)} ä¸ªæœ‰æ•ˆå·¥å…·")
            return tools
            
    except httpx.HTTPStatusError as e:
        logger.error(f"API HTTP é”™è¯¯: {e.response.status_code} - {e.response.url}")
        return []
    except Exception as e:
        logger.error(f"ä»APIè·å–å·¥å…·å¤±è´¥: {e}")
        import traceback
        logger.debug(traceback.format_exc())
        return []


async def _fetch_with_httpx(
    category: Optional[str] = None,
    max_items: int = 100
) -> List[Dict[str, Any]]:
    """ä½¿ç”¨ httpx æŠ“å–å·¥å…·æ•°æ®ï¼ˆå¯èƒ½æ— æ³•è·å–åŠ¨æ€å†…å®¹ï¼‰"""
    base_url = "http://devmaster.cn"
    tools_url = f"{base_url}/tools"
    
    try:
        async with httpx.AsyncClient(
            timeout=30.0,
            headers={
                "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36",
            },
            follow_redirects=True
        ) as client:
            resp = await client.get(tools_url)
            resp.raise_for_status()
            
            soup = BeautifulSoup(resp.text, 'html.parser')
            tools = []
            
            # å°è¯•æŸ¥æ‰¾å·¥å…·å…ƒç´ 
            tool_elements = []
            selectors = [
                "article",
                "[class*='card']",
                "[class*='item']"
            ]
            
            for selector in selectors:
                elements = soup.select(selector)
                if elements:
                    tool_elements = elements
                    break
            
            for element in tool_elements[:max_items]:
                tool = _parse_tool_element(element, base_url)
                if tool:
                    if not category:
                        tool["category"] = _auto_categorize_tool(tool)
                    else:
                        tool["category"] = category
                    tools.append(tool)
            
            return tools
            
    except Exception as e:
        logger.error(f"httpx æŠ“å–å¤±è´¥: {e}")
        return []


def _is_tool_link(link) -> bool:
    """åˆ¤æ–­é“¾æ¥æ˜¯å¦æ˜¯å·¥å…·é“¾æ¥"""
    href = link.get("href", "")
    text = link.get_text(strip=True)
    
    # æ’é™¤ä¸€äº›æ˜æ˜¾ä¸æ˜¯å·¥å…·çš„é“¾æ¥
    exclude_patterns = [
        "/about", "/contact", "/login", "/register", 
        "/privacy", "/terms", "/help", "/faq"
    ]
    
    if any(pattern in href.lower() for pattern in exclude_patterns):
        return False
    
    # å¦‚æœé“¾æ¥æ–‡æœ¬å¤ªçŸ­æˆ–å¤ªé•¿ï¼Œå¯èƒ½ä¸æ˜¯å·¥å…·
    if len(text) < 2 or len(text) > 100:
        return False
    
    return True


def _parse_tool_element(element, base_url: str) -> Optional[Dict[str, Any]]:
    """
    è§£æå•ä¸ªå·¥å…·å…ƒç´ 
    
    Args:
        element: BeautifulSoup å…ƒç´ 
        base_url: åŸºç¡€URL
        
    Returns:
        å·¥å…·å­—å…¸æˆ– None
    """
    try:
        tool = {
            "name": "",
            "url": "",
            "description": "",
            "category": "other",
            "tags": [],
            "icon": "ğŸ”§",
            "view_count": 0,
            "created_at": datetime.now().isoformat() + "Z",
            "is_featured": False
        }
        
        # æŸ¥æ‰¾åç§°å’Œé“¾æ¥
        name_elem = element.find("a", href=True) or element.find("h1") or element.find("h2") or element.find("h3")
        if name_elem:
            if name_elem.name == "a":
                tool["name"] = name_elem.get_text(strip=True)
                href = name_elem.get("href", "")
                tool["url"] = urljoin(base_url, href)
            else:
                tool["name"] = name_elem.get_text(strip=True)
                # å°è¯•åœ¨çˆ¶å…ƒç´ ä¸­æŸ¥æ‰¾é“¾æ¥
                link_elem = element.find("a", href=True)
                if link_elem:
                    href = link_elem.get("href", "")
                    tool["url"] = urljoin(base_url, href)
        
        # å¦‚æœæ²¡æœ‰æ‰¾åˆ°åç§°ï¼Œå°è¯•ä»å…¶ä»–å…ƒç´ è·å–
        if not tool["name"]:
            title_elem = element.find(class_=lambda x: x and ("title" in x.lower() or "name" in x.lower()))
            if title_elem:
                tool["name"] = title_elem.get_text(strip=True)
        
        # æŸ¥æ‰¾æè¿°
        desc_elem = (
            element.find("p") or 
            element.find(class_=lambda x: x and "desc" in x.lower()) or
            element.find(class_=lambda x: x and "summary" in x.lower())
        )
        if desc_elem:
            tool["description"] = desc_elem.get_text(strip=True)
        
        # å¦‚æœæ²¡æœ‰æ‰¾åˆ°æè¿°ï¼Œå°è¯•ä»æ‰€æœ‰æ–‡æœ¬ä¸­æå–
        if not tool["description"]:
            all_text = element.get_text(separator=" ", strip=True)
            # ç§»é™¤åç§°éƒ¨åˆ†
            if tool["name"]:
                all_text = all_text.replace(tool["name"], "", 1).strip()
            # å–å‰200ä¸ªå­—ç¬¦ä½œä¸ºæè¿°
            tool["description"] = all_text[:200] if len(all_text) > 200 else all_text
        
        # æŸ¥æ‰¾æ ‡ç­¾
        tag_elements = element.find_all(class_=lambda x: x and "tag" in x.lower())
        if tag_elements:
            tool["tags"] = [tag.get_text(strip=True) for tag in tag_elements if tag.get_text(strip=True)]
        
        # æŸ¥æ‰¾å›¾æ ‡
        icon_elem = element.find("img") or element.find(class_=lambda x: x and "icon" in x.lower())
        if icon_elem:
            if icon_elem.name == "img":
                icon_src = icon_elem.get("src", "")
                if icon_src:
                    tool["icon"] = urljoin(base_url, icon_src)
            else:
                # å¯èƒ½æ˜¯ emoji æˆ–å­—ä½“å›¾æ ‡
                icon_text = icon_elem.get_text(strip=True)
                if icon_text:
                    tool["icon"] = icon_text[:1]  # å–ç¬¬ä¸€ä¸ªå­—ç¬¦ï¼ˆå¯èƒ½æ˜¯emojiï¼‰
        
        # éªŒè¯å¿…éœ€å­—æ®µ
        if not tool["name"] or not tool["url"]:
            return None
        
        # æ¸…ç†æ•°æ®
        tool["name"] = tool["name"].strip()
        tool["url"] = tool["url"].strip()
        tool["description"] = tool["description"].strip()
        
        return tool
        
    except Exception as e:
        logger.warning(f"è§£æå·¥å…·å…ƒç´ æ—¶å‡ºé”™: {e}")
        return None


def _auto_categorize_tool(tool: Dict[str, Any]) -> str:
    """
    æ ¹æ®å·¥å…·ä¿¡æ¯è‡ªåŠ¨åˆ†ç±»
    
    Args:
        tool: å·¥å…·å­—å…¸
        
    Returns:
        åˆ†ç±»åç§°
    """
    name_lower = tool.get("name", "").lower()
    desc_lower = tool.get("description", "").lower()
    tags_lower = [tag.lower() for tag in tool.get("tags", [])]
    
    combined_text = f"{name_lower} {desc_lower} {' '.join(tags_lower)}"
    
    # æŒ‰ä¼˜å…ˆçº§æ£€æŸ¥æ¯ä¸ªåˆ†ç±»
    for category, keywords in CATEGORY_MAPPING.items():
        if category == "other":
            continue
        for keyword in keywords:
            if keyword.lower() in combined_text:
                return category
    
    return "other"


async def fetch_all_devmaster_tools(use_api: bool = True) -> Dict[str, List[Dict[str, Any]]]:
    """
    æŠ“å–æ‰€æœ‰å·¥å…·å¹¶æŒ‰åˆ†ç±»åˆ†ç»„
    
    Args:
        use_api: æ˜¯å¦ä½¿ç”¨API
    
    Returns:
        æŒ‰åˆ†ç±»åˆ†ç»„çš„å·¥å…·å­—å…¸
    """
    # ä½¿ç”¨APIè·å–æ‰€æœ‰å·¥å…·
    if use_api:
        all_tools = await fetch_tools_from_api()
    else:
        all_tools = await fetch_devmaster_tools(max_items=500, use_api=False)
    
    # æŒ‰åˆ†ç±»åˆ†ç»„
    categorized_tools = {}
    for category in CATEGORY_MAPPING.keys():
        categorized_tools[category] = []
    
    for tool in all_tools:
        category = tool.get("category", "other")
        # å¦‚æœåˆ†ç±»ä¸åœ¨æ˜ å°„ä¸­ï¼Œå°è¯•è‡ªåŠ¨åˆ†ç±»
        if category not in categorized_tools:
            category = _auto_categorize_tool(tool)
        if category not in categorized_tools:
            category = "other"
        categorized_tools[category].append(tool)
    
    # ç»Ÿè®¡
    for category, tools in categorized_tools.items():
        if tools:
            logger.info(f"åˆ†ç±» '{category}': {len(tools)} ä¸ªå·¥å…·")
    
    return categorized_tools

